{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb758e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load images from specified folder path\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image: {img_path} - {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path containing the images\n",
    "folder_path = './images'\n",
    "\n",
    "# Load images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Display the first image\n",
    "if len(images) > 0:\n",
    "    images[0].show()\n",
    "else:\n",
    "    print(\"No images found in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231386b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds class and boundary box data in .xml files \n",
    "def parse_xml_label(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract image size (optional)\n",
    "    size_elem = root.find('size')\n",
    "    width = int(size_elem.find('width').text)\n",
    "    height = int(size_elem.find('height').text)\n",
    "    depth = int(size_elem.find('depth').text)\n",
    "    \n",
    "    # Extract object annotations\n",
    "    annotations = []\n",
    "    for obj_elem in root.findall('object'):\n",
    "        name = obj_elem.find('name').text\n",
    "        bbox_elem = obj_elem.find('bndbox')\n",
    "        xmin = int(bbox_elem.find('xmin').text)\n",
    "        ymin = int(bbox_elem.find('ymin').text)\n",
    "        xmax = int(bbox_elem.find('xmax').text)\n",
    "        ymax = int(bbox_elem.find('ymax').text)\n",
    "        annotations.append({\n",
    "            'name': name,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax\n",
    "        })\n",
    "    \n",
    "    return width, height, depth, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ea7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path containing the XML labels\n",
    "labels_dir = './images'\n",
    "\n",
    "# Load .xml labels for all files in the directory\n",
    "# This is a dictionary object\n",
    "labels = {}\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith('.xml'):\n",
    "        xml_path = os.path.join(labels_dir, filename)\n",
    "        width, height, depth, annotations = parse_xml_label(xml_path)\n",
    "        labels[filename] = {\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'depth': depth,\n",
    "            'annotations': annotations\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class for the data loader for images and labels\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, images, labels, target_size):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(target_size),  # resize the image before converting to a tensor\n",
    "            transforms.ToTensor(),  # then convert to a tensor\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        # Here the index is passed to a list for images but the labels are a dict so the index is \n",
    "        #concverted to a key\n",
    "        label_index = index + 1\n",
    "        key = f\"{label_index}.xml\"  \n",
    "        label = labels[key]\n",
    "    \n",
    "        # Transforms the image into appropriate sized tensor\n",
    "        image = self.transform(image)\n",
    "    \n",
    "        # Convert the annotations to tensors\n",
    "        annotations = label.get('annotations', [])\n",
    "        annotation_tensors = []\n",
    "        # This dictionary is for classification of the defects\n",
    "        class_to_label = {'Point': 0, 'Void': 1, 'Point Defect': 0}\n",
    "\n",
    "        for annotation in annotations:\n",
    "            class_label = class_to_label[annotation.get('name')]\n",
    "            xmin = annotation.get('xmin', 0)\n",
    "            ymin = annotation.get('ymin', 0)\n",
    "            xmax = annotation.get('xmax', 0)\n",
    "            ymax = annotation.get('ymax', 0)\n",
    "            \n",
    "            annotation_tensor = torch.tensor([class_label, xmin, ymin, xmax, ymax])\n",
    "            annotation_tensors.append(annotation_tensor)\n",
    "        \n",
    "        # Pad the annotation tensors to a fixed length\n",
    "        # if images have different number of annotations it causes shape error\n",
    "        max_annotations = 15\n",
    "        while len(annotation_tensors) < max_annotations:\n",
    "            # Append padding annotation\n",
    "            pad_tensor = torch.tensor([-1, -1, -1, -1, -1])  # Padding value\n",
    "            annotation_tensors.append(pad_tensor)\n",
    "        \n",
    "        annotation_tensors = torch.stack(annotation_tensors)  \n",
    "        return image, annotation_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your Dataset\n",
    "dataset = YourDataset(images, labels, (256, 256))\n",
    "\n",
    "# Check the length of your dataset\n",
    "print(f\"Dataset length: {len(dataset)}\")  # should be 2\n",
    "\n",
    "# Load the data from your Dataset\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1)  # batch_size can be adjusted based on your requirement\n",
    "\n",
    "# Get an iterator from the DataLoader\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "# Get the first item\n",
    "first_item = next(data_iter)\n",
    "\n",
    "# first_item now contains the first batch of data from your data_loader.\n",
    "# It's a list where the first element is the image tensor and the second element is the annotations tensor.\n",
    "\n",
    "# If you want to access the first image and its corresponding annotations, you can do:\n",
    "first_image, first_annotations = first_item\n",
    "\n",
    "print(\"First Image shape: \", first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
