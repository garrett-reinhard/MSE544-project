{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb758e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7b7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load images from specified folder path\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image: {img_path} - {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96da801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" mailcap rules found for type \"image/png\"\n",
      "WARNING: You don't seem to have any mimeinfo.cache files.\n",
      "Try running the update-desktop-database command. If you\n",
      "don't have this command you should install the\n",
      "desktop-file-utils package. This package is available from\n",
      "http://freedesktop.org/wiki/Software/desktop-file-utils/\n",
      "No applications found for mimetype: image/png\n",
      "./usr/bin/xdg-open: 882: x-www-browser: Permission denied\n",
      "/usr/bin/xdg-open: 882: firefox: Permission denied\n",
      "/usr/bin/xdg-open: 882: iceweasel: Permission denied\n",
      "/usr/bin/xdg-open: 882: seamonkey: Permission denied\n",
      "/usr/bin/xdg-open: 882: mozilla: Permission denied\n",
      "/usr/bin/xdg-open: 882: epiphany: Permission denied\n",
      "/usr/bin/xdg-open: 882: konqueror: Permission denied\n",
      "/usr/bin/xdg-open: 882: chromium: Permission denied\n",
      "/usr/bin/xdg-open: 882: chromium-browser: Permission denied\n",
      "/usr/bin/xdg-open: 882: google-chrome: Permission denied\n",
      "/usr/bin/xdg-open: 882: www-browser: Permission denied\n",
      "/usr/bin/xdg-open: 882: links2: Permission denied\n",
      "/usr/bin/xdg-open: 882: elinks: Permission denied\n",
      "/usr/bin/xdg-open: 882: links: Permission denied\n",
      "/usr/bin/xdg-open: 882: lynx: Permission denied\n",
      "/usr/bin/xdg-open: 882: w3m: Permission denied\n",
      "xdg-open: no method available for opening '/tmp/tmpi1ymopf4.PNG'\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder path containing the images\n",
    "folder_path = './mos2'\n",
    "\n",
    "# Load images from the folder\n",
    "images = load_images_from_folder(folder_path)\n",
    "\n",
    "# Display the first image\n",
    "if len(images) > 0:\n",
    "    images[0].show()\n",
    "else:\n",
    "    print(\"No images found in the folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231386b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds class and boundary box data in .xml files \n",
    "def parse_xml_label(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Extract image size (optional)\n",
    "    size_elem = root.find('size')\n",
    "    width = int(size_elem.find('width').text)\n",
    "    height = int(size_elem.find('height').text)\n",
    "    depth = int(size_elem.find('depth').text)\n",
    "    \n",
    "    # Extract object annotations\n",
    "    annotations = []\n",
    "    for obj_elem in root.findall('object'):\n",
    "        name = obj_elem.find('name').text\n",
    "        bbox_elem = obj_elem.find('bndbox')\n",
    "        xmin = int(bbox_elem.find('xmin').text)\n",
    "        ymin = int(bbox_elem.find('ymin').text)\n",
    "        xmax = int(bbox_elem.find('xmax').text)\n",
    "        ymax = int(bbox_elem.find('ymax').text)\n",
    "        annotations.append({\n",
    "            'name': name,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax\n",
    "        })\n",
    "    \n",
    "    return width, height, depth, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96ea7e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '797.9999999999998'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.xml\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      9\u001b[0m     xml_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(labels_dir, filename)\n\u001b[0;32m---> 10\u001b[0m     width, height, depth, annotations \u001b[39m=\u001b[39m parse_xml_label(xml_path)\n\u001b[1;32m     11\u001b[0m     labels[filename] \u001b[39m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m: width,\n\u001b[1;32m     13\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m: height,\n\u001b[1;32m     14\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdepth\u001b[39m\u001b[39m'\u001b[39m: depth,\n\u001b[1;32m     15\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m: annotations\n\u001b[1;32m     16\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mparse_xml_label\u001b[0;34m(xml_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m name \u001b[39m=\u001b[39m obj_elem\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[1;32m     16\u001b[0m bbox_elem \u001b[39m=\u001b[39m obj_elem\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mbndbox\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m xmin \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(bbox_elem\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mxmin\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mtext)\n\u001b[1;32m     18\u001b[0m ymin \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(bbox_elem\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mymin\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     19\u001b[0m xmax \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(bbox_elem\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mxmax\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '797.9999999999998'"
     ]
    }
   ],
   "source": [
    "# Specify the directory path containing the XML labels\n",
    "labels_dir = './data'\n",
    "\n",
    "# Load .xml labels for all files in the directory\n",
    "# This is a dictionary object\n",
    "labels = {}\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith('.xml'):\n",
    "        xml_path = os.path.join(labels_dir, filename)\n",
    "        width, height, depth, annotations = parse_xml_label(xml_path)\n",
    "        labels[filename] = {\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'depth': depth,\n",
    "            'annotations': annotations\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c7d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class for the data loader for images and labels\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, images, labels, target_size):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.target_size = target_size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(target_size),  # resize the image before converting to a tensor\n",
    "            transforms.ToTensor(),  # then convert to a tensor\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        # Here the index is passed to a list for images but the labels are a dict so the index is \n",
    "        #concverted to a key\n",
    "        label_index = index + 1\n",
    "        key = f\"{label_index}.xml\"  \n",
    "        label = labels[key]\n",
    "    \n",
    "        # Transforms the image into appropriate sized tensor\n",
    "        image = self.transform(image)\n",
    "    \n",
    "        # Convert the annotations to tensors\n",
    "        annotations = label.get('annotations', [])\n",
    "        annotation_tensors = []\n",
    "        # This dictionary is for classification of the defects\n",
    "        class_to_label = {'Point': 0, 'Void': 1, 'Point Defect': 0}\n",
    "\n",
    "        for annotation in annotations:\n",
    "            class_label = class_to_label[annotation.get('name')]\n",
    "            xmin = annotation.get('xmin', 0)\n",
    "            ymin = annotation.get('ymin', 0)\n",
    "            xmax = annotation.get('xmax', 0)\n",
    "            ymax = annotation.get('ymax', 0)\n",
    "            \n",
    "            annotation_tensor = torch.tensor([class_label, xmin, ymin, xmax, ymax])\n",
    "            annotation_tensors.append(annotation_tensor)\n",
    "        \n",
    "        # Pad the annotation tensors to a fixed length\n",
    "        # if images have different number of annotations it causes shape error\n",
    "        max_annotations = 15\n",
    "        while len(annotation_tensors) < max_annotations:\n",
    "            # Append padding annotation\n",
    "            pad_tensor = torch.tensor([-1, -1, -1, -1, -1])  # Padding value\n",
    "            annotation_tensors.append(pad_tensor)\n",
    "        \n",
    "        annotation_tensors = torch.stack(annotation_tensors)  \n",
    "        return image, annotation_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02fdac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 28\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m data_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(data_loader)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Get the first item\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m first_item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_iter)\n\u001b[1;32m     17\u001b[0m \u001b[39m# first_item now contains the first batch of data from your data_loader.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# It's a list where the first element is the image tensor and the second element is the annotations tensor.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[39m# If you want to access the first image and its corresponding annotations, you can do:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m first_image, first_annotations \u001b[39m=\u001b[39m first_item\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmic/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmic/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmic/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmic/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m, in \u001b[0;36mYourDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m label_index \u001b[39m=\u001b[39m index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     20\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabel_index\u001b[39m}\u001b[39;00m\u001b[39m.xml\u001b[39m\u001b[39m\"\u001b[39m  \n\u001b[0;32m---> 21\u001b[0m label \u001b[39m=\u001b[39m labels[key]\n\u001b[1;32m     23\u001b[0m \u001b[39m# Transforms the image into appropriate sized tensor\u001b[39;00m\n\u001b[1;32m     24\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n",
      "\u001b[0;31mKeyError\u001b[0m: '1.xml'"
     ]
    }
   ],
   "source": [
    "# Create an instance of your Dataset\n",
    "dataset = YourDataset(images, labels, (256, 256))\n",
    "\n",
    "# Check the length of your dataset\n",
    "print(f\"Dataset length: {len(dataset)}\")  # should be 2\n",
    "\n",
    "# Load the data from your Dataset\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=1)  # batch_size can be adjusted based on your requirement\n",
    "\n",
    "# Get an iterator from the DataLoader\n",
    "data_iter = iter(data_loader)\n",
    "\n",
    "# Get the first item\n",
    "first_item = next(data_iter)\n",
    "\n",
    "# first_item now contains the first batch of data from your data_loader.\n",
    "# It's a list where the first element is the image tensor and the second element is the annotations tensor.\n",
    "\n",
    "# If you want to access the first image and its corresponding annotations, you can do:\n",
    "first_image, first_annotations = first_item\n",
    "\n",
    "print(\"First Image shape: \", first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddb401",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image, first_annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
